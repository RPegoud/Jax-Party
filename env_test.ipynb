{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "/home/ryanp/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Sequence, Tuple\n",
    "from jax_party.env import JaxParty, PartyGenerator, PartyMARLWrapper\n",
    "from jax_party.env_types import Action\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import chex\n",
    "import itertools\n",
    "from jax_party.utils import tree_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_state(state):\n",
    "    for key in state.keys():\n",
    "        print(f\"{key}: {state[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_agents: [0 1 1]\n",
      "cumulative_rewards: [0. 4. 2.]\n",
      "ranking: [1 2 0]\n",
      "step_count: 1\n",
      "action_mask: [[False False]\n",
      " [ True  True]\n",
      " [ True  True]]\n",
      "key: [1700909826 1576785425]\n"
     ]
    }
   ],
   "source": [
    "env = JaxParty(generator=PartyGenerator(), time_limit=4000)\n",
    "env = PartyMARLWrapper(env)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "state, timestep = env.reset(key)\n",
    "actions = jnp.array([-1, 0, 0])\n",
    "state, ts = env.step(state, actions)\n",
    "unpack_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_agents: [0 1 1]\n",
      "cumulative_rewards: [0. 6. 6.]\n",
      "ranking: [1 2 0]\n",
      "step_count: 2\n",
      "action_mask: [[False False]\n",
      " [ True  True]\n",
      " [ True  True]]\n",
      "key: [4260505492 1636762242]\n"
     ]
    }
   ],
   "source": [
    "actions = jnp.array([0, 0, 0])\n",
    "state, timestep = env.step(state, actions)\n",
    "unpack_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for actions in jnp.array(list(itertools.permutations([0, 1, 2]))):\n",
    "#     # print(\"active_agents\", state.active_agents)\n",
    "#     # print(\"actions\", actions)\n",
    "#     actions = env._get_valid_actions(actions, state.action_mask)\n",
    "#     # print(\"corrected actions\", actions)\n",
    "#     # state, timestep = env.step(state, actions)\n",
    "#     print(state.cumulative_rewards, state.ranking)\n",
    "#     print(\"-\" * 30)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Observation(agents_view=Array([[0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32), action_mask=Array([[ True, False, False],\n",
       "       [False,  True,  True],\n",
       "       [False,  True,  True]], dtype=bool), step_count=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec.agents_view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Observation(agents_view=Array([False, False, False, False, False, False, False, False, False],      dtype=bool), action_mask=Array([False, False, False], dtype=bool), step_count=Array([0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec.generate_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mava.utils.checkpointing import Checkpointer\n",
    "\n",
    "loaded_checkpoint = Checkpointer(\n",
    "    model_name=config.logger.system_name,\n",
    "    **config.logger.checkpointing.load_args,  # Other checkpoint args\n",
    ")\n",
    "# Restore the learner state from the checkpoint\n",
    "restored_params, _ = loaded_checkpoint.restore_params(\n",
    "    input_params=Params(actor_params, critic_params)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
